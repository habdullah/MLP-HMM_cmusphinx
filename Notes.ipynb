{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Incorporating MLP in sphinx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting off, we'll train a MLP on the walls street journal __wsj__ corpus. This will give us baseline scores.\n",
    "We choose wsj corpus instead of open corpora because we know the accuracy (3%) we have to achieve ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22nd May:** Literature review. output classes of MLP tied states or phone states.According to this paper by J. hinton https://www.clsp.jhu.edu/~samuel/pdfs/scarf_mlp.pdf, Tied states were used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**23rd May:** Writing code to generate log spectra from audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries used:<br>**pysoundfile**<br>**python_speech_features**\n",
    "\n",
    "Pysoundfile reads audio files in flac format and returns an array\n",
    "python_speech_features provides a logfbank method that takes in a linear array and returns filter bank energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from python_speech_features import logfbank\n",
    "import soundfile as sf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for making log feats \n",
    "#path to corpus\n",
    "corpus= '/media/t-rex/F/wsj/wsj0';\n",
    "#this file contains paths to all flac files\n",
    "f = open('flac_paths.txt','w')\n",
    "    \n",
    "for dir_name,subdir_name,files in os.walk(corpus):\n",
    "    \n",
    "    for file in files:\n",
    "        if file.endswith('.flac'):\n",
    "            path_2_file = dir_name+'/'+file;\n",
    "            #print (path_2_file)\n",
    "            f.write(path_2_file+'\\n')\n",
    "            (s,r) =sf.read(path_2_file)\n",
    "            logfeats = logfbank(s,r, winlen=0.025, winstep=0.01, nfilt=40, nfft=1024, lowfreq=250, highfreq=None, preemph=0.97);\n",
    "            np.savetxt('/media/t-rex/F/wsj/wsj_feats/'+file+'.mls',logfeats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**25th May**: Assigning labels to features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries used:<br>**Tensorflow**<br>**keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data prep\n",
    "from random import randint\n",
    "\n",
    "all_feats=[]\n",
    "all_labels=[]\n",
    "\n",
    "root = '/media/t-rex/F/wsj/';\n",
    "feats_file = root+'wsj_feats';\n",
    "for dir_name,subdir_name,files in os.walk(feats_file):\n",
    "    for file in files:\n",
    "        if file.endswith('.mls'):\n",
    "            path_2_file = dir_name+'/'+file;\n",
    "            \n",
    "            #print (path_2_file)\n",
    "            feat = np.loadtxt('/media/t-rex/F/wsj/wsj_feats/'+file)\n",
    "            n_frames  = feat.shape[0]\n",
    "\n",
    "            #assigning random labels \n",
    "            labels = [randint(1,3000) for i in range(n_frames)]\n",
    "            all_labels+=list(labels)\n",
    "            all_feats += list(feat)\n",
    "        \n",
    "print(len(all_feats),len(all_labels))\n",
    "#test/train split\n",
    "for_training = len(all_feats)*0.8\n",
    "Xtrain = all_feats[:for_training]\n",
    "ytrain = all_labels[:for_training]\n",
    "Xtest = all_feats[for_training:]\n",
    "ytest = all_labels[for_training:]\n",
    "\n",
    "#save as compressed array\n",
    "np.savez(root+'data',Xtrain=Xtrain,ytrain=ytrain,Xtest=Xtest,ytest=ytest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#or save as pickle\n",
    "\n",
    "# import pickle\n",
    "# pickle.dump(Xtrain,open(root+\"Xtrain.p\",\"w\"))\n",
    "# pickle.dump(ytrain,open(root+\"ytrain.p\",\"w\"))\n",
    "# pickle.dump(Xtest,open(root+\"Xtest.p\",\"w\"))\n",
    "# pickle.dump(ytest,open(root+\"ytest.p\",\"w\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**May 26th**: Writing MLP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SG\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('data.npz')\n",
    "xtrain=data['Xtrain'];\n",
    "ytrain=data['ytrain']\n",
    "xtest=data['Xtest'];\n",
    "#convert to one hot\n",
    "ytest=data['ytest'];\n",
    "\n",
    "ytrain = to_categorical(ytrain, num_classes = 3000)\n",
    "model = sequential();\n",
    "model.add(Dense(1000, activation='relu', input_dim=40))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3000, activation='softmax'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,epochs=10,batch_size=10000)\n",
    "score = model.evaluate(x_test, y_test, batch_size=10000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**May 27th**: Setting up kaldi to find tied state alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**May 30th**:Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
